{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7555aa3-1569-4598-86d7-5c6cd4f66121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\uzman\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\uzman\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\uzman\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\uzman\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008ddc1-3b9d-431e-8a56-f8378871f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edc09cd5-690f-40f8-8fe5-f6ddd6bdf613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Directory containing handwritten text images\n",
    "dataset_path = r\"C:\\Users\\uzman\\Documents\\code soft\\Task 5\"\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Load the dataset\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        img = preprocess_image(os.path.join(dataset_path, filename))\n",
    "        images.append(img)\n",
    "        labels.append(os.path.splitext(filename)[0])\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "print(f'Total images: {len(images)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6cb68d-b352-472b-8a74-1f1344ed26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "789c7842-2863-4e7a-9235-bdae9e5f6b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_4 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Activation\n",
    "\n",
    "# Model architecture\n",
    "def build_model(vocab_size, embedding_dim=256, rnn_units=512, batch_size=64):\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        LSTM(rnn_units,\n",
    "             return_sequences=True,\n",
    "             stateful=False,  # Change to False unless you have a specific reason to use stateful LSTM\n",
    "             recurrent_initializer='glorot_uniform'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "vocab_size = len(set(labels))\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=64)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a5d55-8ac5-49fc-bafc-19c5589febc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0f369b6-be2f-4bd0-88c4-b7bd5f1ccb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n",
      "Epoch 1/10 loss: 6.907624244689941\n",
      "Starting epoch 2/10\n",
      "Epoch 2/10 loss: 6.90678071975708\n",
      "Starting epoch 3/10\n",
      "Epoch 3/10 loss: 6.905799865722656\n",
      "Starting epoch 4/10\n",
      "Epoch 4/10 loss: 6.904725551605225\n",
      "Starting epoch 5/10\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F4526E27A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 5/10 loss: 6.903481960296631\n",
      "Starting epoch 6/10\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F4526E27A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 6/10 loss: 6.9015583992004395\n",
      "Starting epoch 7/10\n",
      "Epoch 7/10 loss: 6.897881507873535\n",
      "Starting epoch 8/10\n",
      "Epoch 8/10 loss: 6.893133640289307\n",
      "Starting epoch 9/10\n",
      "Epoch 9/10 loss: 6.887988567352295\n",
      "Starting epoch 10/10\n",
      "Epoch 10/10 loss: 6.882984161376953\n"
     ]
    }
   ],
   "source": [
    "# Example training loop\n",
    "def train_model(model, dataset, epochs=10, batch_size=64):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Starting epoch {epoch+1}/{epochs}')\n",
    "        for batch in dataset:\n",
    "            loss = model.train_on_batch(batch['input'], batch['target'])\n",
    "        print(f'Epoch {epoch+1}/{epochs} loss: {loss}')\n",
    "\n",
    "# Prepare the data for training\n",
    "# Assuming that we have a function to create input and target sequences\n",
    "# Here we create a dummy dataset\n",
    "vocab_size = 1000  # Placeholder, replace with len(set(labels)) in actual use\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "batch_size = 64  # Define batch_size here\n",
    "\n",
    "# Create dummy data for input and target sequences\n",
    "dummy_input = np.random.randint(vocab_size, size=(batch_size, 100))  # replace with real data\n",
    "dummy_target = np.random.randint(vocab_size, size=(batch_size, 100))  # replace with real data\n",
    "\n",
    "# Package data into the dataset\n",
    "dataset = [{'input': dummy_input, 'target': dummy_target}]\n",
    "\n",
    "# Build the model\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataset, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "063dd923-abfe-44cb-b875-3deae619fadd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'T' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[0;32m     21\u001b[0m start_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOJIHKaMV1KPOBb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generate_text(model, start_string)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_text)\n",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(model, start_string, num_generate)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(model, start_string, num_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     input_eval \u001b[38;5;241m=\u001b[39m [labels\u001b[38;5;241m.\u001b[39mindex(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m start_string]\n\u001b[0;32m      3\u001b[0m     input_eval \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(input_eval, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m     text_generated \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(model, start_string, num_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     input_eval \u001b[38;5;241m=\u001b[39m [labels\u001b[38;5;241m.\u001b[39mindex(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m start_string]\n\u001b[0;32m      3\u001b[0m     input_eval \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(input_eval, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m     text_generated \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: 'T' is not in list"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, num_generate=1000):\n",
    "    input_eval = [labels.index(s) for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(labels[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "# Generate text\n",
    "start_string = \"TOJIHKaMV1KPOBb\"\n",
    "generated_text = generate_text(model, start_string)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c83706-aa68-4b14-b717-1a31ef9493bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
